<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Julia Package Listing - Testing Information</title>

    <style>/* -- Mix of julialang.org, Bootstrap 3, and custom -- */
body {
  background-color: white;
  font-family: Georgia, 'Liberation Serif', serif;
  font-size: 14px;
  color: #333;
  line-height: 1.42857143;
}
.site {
  max-width: 785px;
  margin: 2.5em auto 2em;
  padding: 0 1.5em;
}
a {
  color: #428bca;
  text-decoration: none;
}
h1, h2, h3, h4, h5, h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1, h2, h3 {
    margin-top: 20px;
    margin-bottom: 10px;
}
h2 {
  font-size: 30px;
}
h3 {
    font-size: 24px;
}
h4 {
  font-size: 18px;
  margin-top: 10px;
  margin-bottom: 10px;
}
.titlebox {
  text-align: center;
  font-size: 120%;
  margin-top: 3em;
}
.ok     { background-color: #11AA11; } /*Tests passing*/
.fail   { background-color: #DD3333; } /*Tests failed*/
.skip   { background-color: #3333DD; } /*Tests skipped*/
.kill   { background-color: #222222; } /*Tests interrupted*/
.statusbox {
  width: 12px;
  height: 12px;
  display: inline-block;
}
hr {
  margin-top: 10px;
  margin-bottom: 0px;
  border: 0;
  border-top: 1px solid #eee;
}
.pkglisting h2 { margin-bottom: 0px; }
pre {margin: 0;}
@media (min-width: 785px) {
  .pkglisting {
    display: table;
    width: 100%;
  }
  .pkgnamedesc {
    display: table-cell;
    width: 50%;
  }
  .pkgvertest {
    display: table-cell;
    width:50%;
    text-align: right
  }
}
/* collapsible sections */
.collapsible {
  font-family: Georgia, 'Liberation Serif', serif;
  font-size: 14px;
  background: none;
  border: none;
  margin: 0;
  padding: 0;
  cursor: pointer;
}
.content {
  display: none;
  overflow: hidden;
}
</style>
  </head>

  <body>
  <div class="site">
    <!-- HEADER -->
    <div class="titlebox">
        <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="210px" height="142px" viewBox="0 0 310 216" enable-background="new 0 0 310 216" xml:space="preserve">

<!-- blue dot -->
<circle fill="#6b85dd" stroke="#4266d5" stroke-width="3" cx="50.5" cy="58.665" r="16.5"></circle>
<!-- red dot -->
<circle fill="#d66661" stroke="#c93d39" stroke-width="3" cx="212.459" cy="60.249" r="16.5"></circle>
<!-- green dot -->
<circle fill="#6bab5b" stroke="#3b972e" stroke-width="3" cx="233.834" cy="23.874" r="16.5"></circle>
<!-- purple dot -->
<circle fill="#aa7dc0" stroke="#945bb0" stroke-width="3" cx="255.459" cy="59.999" r="16.5"></circle>

<!-- "j" -->
<path fill="#252525" d="M37.216,138.427c0-15.839,0.006-31.679-0.018-47.517c-0.001-0.827,0.169-1.234,1.043-1.47
    c7.876-2.127,15.739-4.308,23.606-6.47c1.33-0.366,1.333-0.36,1.333,1.019c0,25.758,0.015,51.517-0.012,77.274
    c-0.006,5.514,0.245,11.032-0.272,16.543c-0.628,6.69-2.15,13.092-6.438,18.506c-3.781,4.771-8.898,7.25-14.767,8.338
    c-6.599,1.222-13.251,1.552-19.934,0.938c-4.616-0.423-9.045-1.486-12.844-4.363c-2.863-2.168-4.454-4.935-3.745-8.603
    c0.736-3.806,3.348-5.978,6.861-7.127c2.262-0.74,4.628-0.872,6.994-0.53c1.823,0.264,3.42,1.023,4.779,2.288
    c1.38,1.284,2.641,2.674,3.778,4.177c0.872,1.15,1.793,2.256,2.991,3.086c2.055,1.426,4,0.965,5.213-1.216
    c0.819-1.473,0.997-3.106,1.173-4.731c0.255-2.348,0.255-4.707,0.256-7.062C37.218,167.145,37.216,152.786,37.216,138.427z"></path>

<!-- "u" -->
<path fill="#252525" d="M125.536,162.479c-2.908,2.385-5.783,4.312-8.88,5.904c-10.348,5.323-20.514,4.521-30.324-1.253
    c-6.71-3.95-11.012-9.849-12.52-17.606c-0.236-1.213-0.363-2.438-0.363-3.688c0.01-19.797,0.017-39.593-0.02-59.39
    c-0.002-1.102,0.285-1.357,1.363-1.351c7.798,0.049,15.597,0.044,23.396,0.003c0.95-0.005,1.177,0.25,1.175,1.183
    c-0.027,19.356-0.025,38.713-0.018,58.07c0.002,6.34,3.599,10.934,9.672,12.42c2.13,0.521,4.19,0.396,6.173-0.6
    c4.26-2.139,7.457-5.427,10.116-9.307c0.333-0.487,0.224-1,0.224-1.51c0.007-19.635,0.016-39.271-0.02-58.904
    c-0.002-1.083,0.255-1.369,1.353-1.361c7.838,0.052,15.677,0.045,23.515,0.004c0.916-0.005,1.103,0.244,1.102,1.124
    c-0.025,27.677-0.026,55.353,0.002,83.024c0.001,0.938-0.278,1.099-1.139,1.095c-7.918-0.028-15.837-0.028-23.756-0.001
    c-0.815,0.003-1.1-0.166-1.073-1.037C125.581,167.117,125.536,164.928,125.536,162.479z"></path>

<!-- "l" -->
<path fill="#252525" d="M187.423,107.08c0,20.637-0.011,41.273,0.026,61.91c0.003,1.119-0.309,1.361-1.381,1.355
    c-7.799-0.052-15.598-0.047-23.396-0.008c-0.898,0.008-1.117-0.222-1.115-1.115c0.021-39.074,0.021-78.147,0-117.226
    c0-0.811,0.189-1.169,1.006-1.392c7.871-2.149,15.73-4.327,23.584-6.545c1.045-0.295,1.308-0.17,1.306,0.985
    C187.412,65.727,187.423,86.403,187.423,107.08z"></path>

<!-- "i" -->
<path fill="#252525" d="M223.46,126.477c0,14.155-0.011,28.312,0.021,42.467c0.002,1.027-0.164,1.418-1.332,1.408
    c-7.838-0.061-15.676-0.047-23.516-0.01c-0.881,0.004-1.121-0.189-1.119-1.104c0.026-26.153,0.025-52.307,0-78.458
    c0-0.776,0.203-1.101,0.941-1.302c7.984-2.172,15.972-4.35,23.938-6.596c1.049-0.296,1.08,0.031,1.078,0.886
    C223.454,98.004,223.46,112.239,223.46,126.477z"></path>

<!-- "a" -->
<path fill="#252525" d="M277.695,163.6c-0.786,0.646-1.404,1.125-2,1.635c-4.375,3.746-9.42,5.898-15.16,6.42
    c-5.792,0.527-11.479,0.244-16.934-2.047c-12.08-5.071-15.554-17.188-11.938-27.448c1.799-5.111,5.472-8.868,9.831-11.94
    c5.681-4.003,12.009-6.732,18.504-9.074c5.576-2.014,11.186-3.939,16.955-5.347c0.445-0.104,0.773-0.243,0.757-0.854
    c-0.136-4.389,0.261-8.79-0.479-13.165c-1.225-7.209-6.617-10.013-12.895-9.348c-0.516,0.055-1.029,0.129-1.536,0.241
    c-4.877,1.081-7.312,4.413-7.374,10.127c-0.02,1.729-0.229,3.418-0.693,5.084c-0.906,3.229-2.969,5.354-6.168,6.266
    c-3.422,0.979-6.893,0.998-10.23-0.305c-6.529-2.543-8.877-10.164-5.12-16.512c2.249-3.799,5.606-6.4,9.461-8.405
    c6.238-3.246,12.914-4.974,19.896-5.537c7.565-0.61,15.096-0.366,22.49,1.507c4.285,1.085,8.312,2.776,11.744,5.657
    c4.473,3.749,6.776,8.647,6.812,14.374c0.139,21.477,0.096,42.951,0.143,64.428c0.002,0.799-0.248,0.983-1.021,0.98
    c-8.035-0.025-16.074-0.023-24.113-0.001c-0.716,0.002-0.973-0.146-0.941-0.915C277.736,167.562,277.695,165.698,277.695,163.6z
     M277.695,126.393c-4.793,2.104-9.25,4.373-13.287,7.408c-2.151,1.618-4.033,3.483-5.732,5.581
    c-4.229,5.226-1.988,13.343,1.693,16.599c1.592,1.406,3.359,1.906,5.419,1.521c1.621-0.307,3.149-0.857,4.549-1.734
    c1.521-0.951,2.949-2.072,4.539-2.887c2.31-1.18,2.97-2.861,2.894-5.445C277.561,140.484,277.695,133.527,277.695,126.393z"></path>

</svg>

        <h1>
          <a name="AugmentedGaussianProcesses">AugmentedGaussianProcesses</a>
        </h1>

        <p>
          <a href="../index.html#AugmentedGaussianProcesses">â† Back to package list</a>
        </p>

    </div>

    <p>
      If you think that there is an error in how your package is being tested or represented, please file an issue at <a href="https://github.com/JuliaComputing/NewPkgEval.jl">NewPkgEval.jl</a>, making sure to read the FAQ first.
    </p>


    <h3>Results with Julia v1.2.0</h3>

    <p>
      Testing was <strong>successful</strong>.
      Last evaluation was  ago and took 39 minutes, 51 seconds.
    </p>

    <p>
      Click <a href="/home/maleadt/Julia/pkg/NewPkgEval/site/build/logs/AugmentedGaussianProcesses/1.2.0.log">here</a> to download the log file.
      
    </p>

      <button class="collapsible">Click here to show the log contents.</button>
      <div class="content">
      <pre> Resolving package versions...
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed Showoff â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed TableTraits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed NearestNeighbors â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.4
 Installed LineSearches â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v7.0.1
 Installed DataFrames â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.19.4
 Installed AugmentedGaussianProcesses â”€â”€ v0.6.0
 Installed BinaryProvider â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.8
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed AbstractFFTs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.0
 Installed RangeArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.0
 Installed CommonSubexpressions â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.0
 Installed Conda â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.3.0
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed ArrayLayouts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.1.5
 Installed AxisAlgorithms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed Requires â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.2
 Installed DataValueInterfaces â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed InplaceOps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.0
 Installed NLSolversBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v7.5.0
 Installed Reexport â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.0
 Installed InvertedIndices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed PooledArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.2
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed OffsetArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.11.2
 Installed OrderedCollections â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed ForwardDiff â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.10.7
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed IterTools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.3.0
 Installed AdvancedHMC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.14
 Installed Tables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.11
 Installed Calculus â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed KernelDensity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.0
 Installed Parsers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.10
 Installed DataStructures â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.17.6
 Installed ArgCheck â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.1
 Installed Distributions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.21.9
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed DiffEqDiffTools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.5.0
 Installed DiffRules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.1.0
 Installed Ratios â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.21.0
 Installed FastGaussQuadrature â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed NaNMath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.3
 Installed ArrayInterface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.0.0
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed DiffResults â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.0.4
 Installed MCMCChains â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.15
 Installed FFTW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed IntervalSets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.2
 Installed IteratorInterfaceExtensions â”€ v1.0.0
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.1.1
 Installed CategoricalArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.3
 Installed WoodburyMatrices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed GradDescent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed Interpolations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed SortingAlgorithms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed VersionParsing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.3
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
 Installed LazyArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.14.10
 Installed KernelFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.1
 Installed MacroTools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.2
 Installed PositiveFactorizations â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.10
 Installed AxisArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.3
 Installed SpecialFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.0
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed Optim â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.19.5
 Installed ProgressMeter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.2.0
  Updating `~&#x2F;.julia&#x2F;environments&#x2F;v1.2&#x2F;Project.toml`
  [38eea1fd] + AugmentedGaussianProcesses v0.6.0
  Updating `~&#x2F;.julia&#x2F;environments&#x2F;v1.2&#x2F;Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [0bf59076] + AdvancedHMC v0.2.14
  [dce04be8] + ArgCheck v1.0.1
  [7d9fca2a] + Arpack v0.3.1
  [4fba245c] + ArrayInterface v2.0.0
  [4c555306] + ArrayLayouts v0.1.5
  [38eea1fd] + AugmentedGaussianProcesses v0.6.0
  [13072b0f] + AxisAlgorithms v1.0.0
  [39de3d68] + AxisArrays v0.3.3
  [9e28174c] + BinDeps v0.8.10
  [b99e7846] + BinaryProvider v0.5.8
  [49dc2e85] + Calculus v0.5.1
  [324d7699] + CategoricalArrays v0.7.3
  [aaaa29a8] + Clustering v0.13.3
  [bbf7d656] + CommonSubexpressions v0.2.0
  [34da2185] + Compat v2.2.0
  [8f4d0f93] + Conda v1.3.0
  [9a962f9c] + DataAPI v1.1.0
  [a93c6f00] + DataFrames v0.19.4
  [864edb3b] + DataStructures v0.17.6
  [e2d170a0] + DataValueInterfaces v1.0.0
  [01453d9d] + DiffEqDiffTools v1.5.0
  [163ba53b] + DiffResults v0.0.4
  [b552c78f] + DiffRules v0.1.0
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.9
  [7a1cc6ca] + FFTW v1.1.0
  [442a2c76] + FastGaussQuadrature v0.4.1
  [1a297f60] + FillArrays v0.8.2
  [f6369f11] + ForwardDiff v0.10.7
  [e1397348] + GradDescent v0.3.1
  [505f98c9] + InplaceOps v0.3.0
  [a98d9a8b] + Interpolations v0.12.5
  [8197267c] + IntervalSets v0.3.2
  [41ab1584] + InvertedIndices v1.0.0
  [c8e1da08] + IterTools v1.3.0
  [82899510] + IteratorInterfaceExtensions v1.0.0
  [682c06a0] + JSON v0.21.0
  [5ab0869b] + KernelDensity v0.5.1
  [ec8451be] + KernelFunctions v0.2.1
  [5078a376] + LazyArrays v0.14.10
  [d3d80556] + LineSearches v7.0.1
  [c7f686f2] + MCMCChains v0.3.15
  [1914dd2f] + MacroTools v0.5.2
  [e1d29d7a] + Missings v0.4.3
  [d41bc354] + NLSolversBase v7.5.0
  [77ba4419] + NaNMath v0.3.3
  [b8a86587] + NearestNeighbors v0.4.4
  [6fe1bfb0] + OffsetArrays v0.11.2
  [429524aa] + Optim v0.19.5
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [69de0a69] + Parsers v0.3.10
  [2dfb63ee] + PooledArrays v0.5.2
  [85a6dd25] + PositiveFactorizations v0.2.3
  [92933f4c] + ProgressMeter v1.2.0
  [1fd47b50] + QuadGK v2.1.1
  [b3c3ace0] + RangeArrays v0.3.1
  [c84ed2f1] + Ratios v0.3.1
  [3cdcf5f2] + RecipesBase v0.7.0
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v0.5.2
  [79098fc4] + Rmath v0.6.0
  [992d4aef] + Showoff v0.3.1
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.8.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.8.0
  [3783bdb8] + TableTraits v1.0.0
  [bd369af6] + Tables v0.2.11
  [30578b45] + URIParser v0.4.0
  [81def892] + VersionParsing v1.1.3
  [efce3f68] + WoodburyMatrices v0.4.1
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [9fa8497b] + Future 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Conda â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~&#x2F;.julia&#x2F;packages&#x2F;Conda&#x2F;kLXeC&#x2F;deps&#x2F;build.log`
  Building Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~&#x2F;.julia&#x2F;packages&#x2F;Rmath&#x2F;BoBag&#x2F;deps&#x2F;build.log`
  Building FFTW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~&#x2F;.julia&#x2F;packages&#x2F;FFTW&#x2F;loJ3F&#x2F;deps&#x2F;build.log`
  Building SpecialFunctions â†’ `~&#x2F;.julia&#x2F;packages&#x2F;SpecialFunctions&#x2F;ne2iw&#x2F;deps&#x2F;build.log`
  Building Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~&#x2F;.julia&#x2F;packages&#x2F;Arpack&#x2F;cu5By&#x2F;deps&#x2F;build.log`
   Testing AugmentedGaussianProcesses
 Resolving package versions...
    Status `&#x2F;tmp&#x2F;jl_sjNHeF&#x2F;Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [0bf59076] AdvancedHMC v0.2.14
  [dce04be8] ArgCheck v1.0.1
  [7d9fca2a] Arpack v0.3.1
  [4fba245c] ArrayInterface v2.0.0
  [4c555306] ArrayLayouts v0.1.5
  [38eea1fd] AugmentedGaussianProcesses v0.6.0
  [13072b0f] AxisAlgorithms v1.0.0
  [39de3d68] AxisArrays v0.3.3
  [9e28174c] BinDeps v0.8.10
  [b99e7846] BinaryProvider v0.5.8
  [49dc2e85] Calculus v0.5.1
  [324d7699] CategoricalArrays v0.7.3
  [aaaa29a8] Clustering v0.13.3
  [bbf7d656] CommonSubexpressions v0.2.0
  [34da2185] Compat v2.2.0
  [8f4d0f93] Conda v1.3.0
  [9a962f9c] DataAPI v1.1.0
  [a93c6f00] DataFrames v0.19.4
  [864edb3b] DataStructures v0.17.6
  [e2d170a0] DataValueInterfaces v1.0.0
  [01453d9d] DiffEqDiffTools v1.5.0
  [163ba53b] DiffResults v0.0.4
  [b552c78f] DiffRules v0.1.0
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.9
  [7a1cc6ca] FFTW v1.1.0
  [442a2c76] FastGaussQuadrature v0.4.1
  [1a297f60] FillArrays v0.8.2
  [f6369f11] ForwardDiff v0.10.7
  [e1397348] GradDescent v0.3.1
  [505f98c9] InplaceOps v0.3.0
  [a98d9a8b] Interpolations v0.12.5
  [8197267c] IntervalSets v0.3.2
  [41ab1584] InvertedIndices v1.0.0
  [c8e1da08] IterTools v1.3.0
  [82899510] IteratorInterfaceExtensions v1.0.0
  [682c06a0] JSON v0.21.0
  [5ab0869b] KernelDensity v0.5.1
  [ec8451be] KernelFunctions v0.2.1
  [5078a376] LazyArrays v0.14.10
  [d3d80556] LineSearches v7.0.1
  [c7f686f2] MCMCChains v0.3.15
  [1914dd2f] MacroTools v0.5.2
  [e1d29d7a] Missings v0.4.3
  [d41bc354] NLSolversBase v7.5.0
  [77ba4419] NaNMath v0.3.3
  [b8a86587] NearestNeighbors v0.4.4
  [6fe1bfb0] OffsetArrays v0.11.2
  [429524aa] Optim v0.19.5
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [69de0a69] Parsers v0.3.10
  [2dfb63ee] PooledArrays v0.5.2
  [85a6dd25] PositiveFactorizations v0.2.3
  [92933f4c] ProgressMeter v1.2.0
  [1fd47b50] QuadGK v2.1.1
  [b3c3ace0] RangeArrays v0.3.1
  [c84ed2f1] Ratios v0.3.1
  [3cdcf5f2] RecipesBase v0.7.0
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v0.5.2
  [79098fc4] Rmath v0.6.0
  [992d4aef] Showoff v0.3.1
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.8.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.8.0
  [3783bdb8] TableTraits v1.0.0
  [bd369af6] Tables v0.2.11
  [30578b45] URIParser v0.4.0
  [81def892] VersionParsing v1.1.3
  [efce3f68] WoodburyMatrices v0.4.1
  [2a0f44e3] Base64  [`@stdlib&#x2F;Base64`]
  [ade2ca70] Dates  [`@stdlib&#x2F;Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib&#x2F;DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib&#x2F;Distributed`]
  [9fa8497b] Future  [`@stdlib&#x2F;Future`]
  [b77e0a4c] InteractiveUtils  [`@stdlib&#x2F;InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib&#x2F;LibGit2`]
  [8f399da3] Libdl  [`@stdlib&#x2F;Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib&#x2F;LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib&#x2F;Logging`]
  [d6f4376e] Markdown  [`@stdlib&#x2F;Markdown`]
  [a63ad114] Mmap  [`@stdlib&#x2F;Mmap`]
  [44cfe95a] Pkg  [`@stdlib&#x2F;Pkg`]
  [de0858da] Printf  [`@stdlib&#x2F;Printf`]
  [3fa0cd96] REPL  [`@stdlib&#x2F;REPL`]
  [9a3f8284] Random  [`@stdlib&#x2F;Random`]
  [ea8e919c] SHA  [`@stdlib&#x2F;SHA`]
  [9e88b42a] Serialization  [`@stdlib&#x2F;Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib&#x2F;SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib&#x2F;Sockets`]
  [2f01184e] SparseArrays  [`@stdlib&#x2F;SparseArrays`]
  [10745b16] Statistics  [`@stdlib&#x2F;Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib&#x2F;SuiteSparse`]
  [8dfed614] Test  [`@stdlib&#x2F;Test`]
  [cf7118a7] UUIDs  [`@stdlib&#x2F;UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib&#x2F;Unicode`]
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lstirling_asym(::BigFloat) at misc.jl:56
â”” @ StatsFuns ~&#x2F;.julia&#x2F;packages&#x2F;StatsFuns&#x2F;2QE7p&#x2F;src&#x2F;misc.jl:56
WARNING: Method definition deepcopy(GradDescent.Optimizer) in module GradDescent at &#x2F;root&#x2F;.julia&#x2F;packages&#x2F;GradDescent&#x2F;C4qjb&#x2F;src&#x2F;AbstractOptimizer.jl:22 overwritten in module AugmentedGaussianProcesses at &#x2F;root&#x2F;.julia&#x2F;packages&#x2F;AugmentedGaussianProcesses&#x2F;8kAgJ&#x2F;src&#x2F;functions&#x2F;utils.jl:71.
  ** incremental compilation may be fatally broken for this module **

Starting training Gaussian Process with a Gaussian likelihood infered by Analytic Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:06:52[K
  iter:  10
  ELBO:  624.055311605656[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:04:01[K
  iter:  20
  ELBO:  635.674952676726[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:02:55[K
  iter:  30
  ELBO:  589.8717573550398[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:02:31[K
  iter:  40
  ELBO:  662.1781749152855[A[ATraining ended after 50 iterations. Total number of iterations 50


[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:02:09[K
  iter:  50
  ELBO:  623.4231417439881[A[AStarting training Variational Gaussian Process with a Student-t likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:24:08[K
  iter:  10
  ELBO:  -152.22527095522128[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:14:44[K
  iter:  20
  ELBO:  -150.83076430626713[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:10:17[K
  iter:  30
  ELBO:  -149.87410204825002[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:09:30[K
  iter:  40
  ELBO:  -149.3256010303905[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:09:00[K
  iter:  50
  ELBO:  -149.09330240808055[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.4242331022347892
Starting training Variational Gaussian Process with a Laplace likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:11:16[K
  iter:  10
  ELBO:  -566.225785866745[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:11:49[K
  iter:  20
  ELBO:  -568.6837211638668[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:11:11[K
  iter:  30
  ELBO:  -570.2704750617578[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:10:32[K
  iter:  40
  ELBO:  -571.5108565720788[A[ATraining ended after 50 iterations. Total number of iterations 50


[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:10:18[K
  iter:  50
  ELBO:  -572.6758898614879[A[Aâ”Œ Info: Regression Error
â””   err = 0.4018312504927594
Starting training Variational Gaussian Process with a Gaussian likelihood with heteroscedastic noise infered by Analytic Variational Inference  with 100 samples with 2 features and 2 latent GPs
Training Progress:   2%|â–‹                               |  ETA: 0:17:41[K
  iter:  10
  ELBO:  -151.91804200759827[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:18:21[K
  iter:  20
  ELBO:  -148.2628097629236[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:16:56[K
  iter:  30
  ELBO:  -145.8411732543865[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:17:41[K
  iter:  40
  ELBO:  -143.96603507455967[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:17:32[K
  iter:  50
  ELBO:  -142.6234705895817[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.6697049944690828
Starting training Variational Gaussian Process with a Bayesian SVM infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:06:59[K
  iter:  10
  ELBO:  69.36594915002166[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:07:25[K
  iter:  20
  ELBO:  81.76959815148342[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:07:21[K
  iter:  30
  ELBO:  93.11305693561144[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:06:35[K
  iter:  40
  ELBO:  102.88460405829255[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:06:07[K
  iter:  50
  ELBO:  111.76775053363693[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Classification Error
â””   err = 0.02
Starting training Variational Gaussian Process with a Bernoulli Likelihood with Logistic Link infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:10:45[K
  iter:  10
  ELBO:  -15.45496403516649[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:10:19[K
  iter:  20
  ELBO:  -12.921811247704284[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:08:03[K
  iter:  30
  ELBO:  -10.525979508342859[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:07:45[K
  iter:  40
  ELBO:  -8.358200907239684[A[ATraining ended after 50 iterations. Total number of iterations 50


[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:06:59[K
  iter:  50
  ELBO:  -6.4397859300417934[A[Aâ”Œ Info: Classification Error
â””   err = 0.06
Starting training Variational Gaussian Process with a Logistic-Softmax Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 5 latent GPs
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = mapreduce_impl(::typeof(SpecialFunctions.lgamma), ::typeof(Base.add_sum), ::Array{Float64,1}, ::Int64, ::Int64, ::Int64) at reduce.jl:163
â”” @ Base .&#x2F;reduce.jl:163
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = mapreduce_impl(::typeof(SpecialFunctions.lgamma), ::typeof(Base.add_sum), ::Array{Float64,1}, ::Int64, ::Int64, ::Int64) at reduce.jl:163
â”” @ Base .&#x2F;reduce.jl:163
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = macro expansion at reduce.jl:166 [inlined]
â”” @ Core .&#x2F;reduce.jl:166
Training Progress:   2%|â–‹                               |  ETA: 0:33:54[K
  iter:  10
  ELBO:  -35.3935785497838[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:35:29[K
  iter:  20
  ELBO:  -34.450206095421095[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:34:21[K
  iter:  30
  ELBO:  -33.48761577222891[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:36:55[K
  iter:  40
  ELBO:  -32.511984642637856[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:40:36[K
  iter:  50
  ELBO:  -31.53238843149282[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Multiclass Error
â””   err = 0.27
Starting training Variational Gaussian Process with a Poisson Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapreduce_impl(::typeof(SpecialFunctions.lfactorial), ::typeof(Base.add_sum), ::SubArray{Int64,1,Array{Int64,1},Tuple{UnitRange{Int64}},true}, ::Int64, ::Int64, ::Int64) at reduce.jl:163
â”” @ Base .&#x2F;reduce.jl:163
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapreduce_impl(::typeof(SpecialFunctions.lfactorial), ::typeof(Base.add_sum), ::SubArray{Int64,1,Array{Int64,1},Tuple{UnitRange{Int64}},true}, ::Int64, ::Int64, ::Int64) at reduce.jl:163
â”” @ Base .&#x2F;reduce.jl:163
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = macro expansion at reduce.jl:166 [inlined]
â”” @ Core .&#x2F;reduce.jl:166
Training Progress:   2%|â–‹                               |  ETA: 0:10:29[K
  iter:  10
  ELBO:  -127.88298349900538[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:11:36[K
  iter:  20
  ELBO:  -127.29460423970174[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:09:30[K
  iter:  30
  ELBO:  -126.78849653826994[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:09:12[K
  iter:  40
  ELBO:  -126.35342619265279[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:09:15[K
  iter:  50
  ELBO:  -125.97784291753513[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 0.7098173135397451
Starting training Variational Gaussian Process with a Negative Binomial Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:10:41[K
  iter:  10
  ELBO:  -721.0880180049668[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:11:11[K
  iter:  20
  ELBO:  -722.0593597319065[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:09:31[K
  iter:  30
  ELBO:  -724.9942368244377[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:09:10[K
  iter:  40
  ELBO:  -729.9041714833297[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:08:41[K
  iter:  50
  ELBO:  -736.0449100226631[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 17.843017416604514
Starting training Sparse Variational Gaussian Process with a Gaussian likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:17:41[K
  iter:  10
  ELBO:  -17079.797227277842[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:11:02[K
  iter:  20
  ELBO:  -8599.597977234811[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:07:25[K
  iter:  30
  ELBO:  -5242.010884223601[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:04:29[K
  iter:  50
  ELBO:  -2128.361384061914[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.19166431205933365
Starting training Sparse Variational Gaussian Process with a Gaussian likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:09:54[K
  iter:  10
  ELBO:  -9899.639904103531[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:07:41[K
  iter:  20
  ELBO:  -5426.539173392311[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:06:34[K
  iter:  30
  ELBO:  -2843.9384952479813[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:05:40[K
  iter:  40
  ELBO:  -1750.2504312954447[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:04:39[K
  iter:  50
  ELBO:  -1244.9903501916276[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.19240798383401675
Starting training Sparse Variational Gaussian Process with a Student-t likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:04:39[K
  iter:  10
  ELBO:  -154.46487995526215[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:06:03[K
  iter:  20
  ELBO:  -154.20442389905529[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:05:15[K
  iter:  30
  ELBO:  -148.27646371341282[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:05:26[K
  iter:  40
  ELBO:  -144.721419278619[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:05:04[K
  iter:  50
  ELBO:  -149.6070600895724[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.37437043455267
Starting training Sparse Variational Gaussian Process with a Student-t likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:03:05[K
  iter:  10
  ELBO:  -153.04344847573242[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:04:29[K
  iter:  20
  ELBO:  -149.99639403772224[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:05:19[K
  iter:  30
  ELBO:  -147.7602417610451[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:05:17[K
  iter:  40
  ELBO:  -146.24357901950046[A[ATraining ended after 50 iterations. Total number of iterations 50


[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:05:03[K
  iter:  50
  ELBO:  -145.29013276252704[A[Aâ”Œ Info: Regression Error
â””   err = 0.41590173469563896
Starting training Sparse Variational Gaussian Process with a Laplace likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:06:07[K
  iter:  10
  ELBO:  -484.54426228743625[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:06:43[K
  iter:  20
  ELBO:  -508.1824957786268[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:06:50[K
  iter:  30
  ELBO:  -529.6422203331739[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:07:06[K
  iter:  40
  ELBO:  -535.1785651152693[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:07:07[K
  iter:  50
  ELBO:  -539.2752458689331[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.36679289894619643
Starting training Sparse Variational Gaussian Process with a Laplace likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:05:25[K
  iter:  10
  ELBO:  -532.2261019516801[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:07:48[K
  iter:  20
  ELBO:  -541.9117945690705[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:08:28[K
  iter:  30
  ELBO:  -550.4257458267432[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:08:19[K
  iter:  40
  ELBO:  -557.2638921738726[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:08:15[K
  iter:  50
  ELBO:  -562.3300006862518[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.4045807937532465
Starting training Sparse Variational Gaussian Process with a Bayesian SVM infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:07:29[K
  iter:  10
  ELBO:  65.9218130002265[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:07:20[K
  iter:  20
  ELBO:  76.82715598619467[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:07:18[K
  iter:  30
  ELBO:  73.98349532366115[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:07:07[K
  iter:  40
  ELBO:  74.00915532136801[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:06:59[K
  iter:  50
  ELBO:  97.50413919760484[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Classification Error
â””   err = 0.08
Starting training Sparse Variational Gaussian Process with a Bayesian SVM infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:07:22[K
  iter:  10
  ELBO:  68.98355584076893[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:05:53[K
  iter:  20
  ELBO:  76.78745658806402[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:05:57[K
  iter:  30
  ELBO:  84.52423904711736[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:06:18[K
  iter:  40
  ELBO:  92.2066783805736[A[ATraining ended after 50 iterations. Total number of iterations 50


[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:06:32[K
  iter:  50
  ELBO:  99.92516828116736[A[Aâ”Œ Info: Classification Error
â””   err = 0.1
Starting training Sparse Variational Gaussian Process with a Bernoulli Likelihood with Logistic Link infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:07:58[K
  iter:  10
  ELBO:  -27.751042546926456[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:07:28[K
  iter:  20
  ELBO:  -28.644634401176216[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:07:49[K
  iter:  30
  ELBO:  -27.546234465921838[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:07:11[K
  iter:  40
  ELBO:  -30.514751102705365[A[ATraining ended after 50 iterations. Total number of iterations 50


[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:07:14[K
  iter:  50
  ELBO:  -24.39375109216409[A[Aâ”Œ Info: Classification Error
â””   err = 0.09
Starting training Sparse Variational Gaussian Process with a Bernoulli Likelihood with Logistic Link infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:04:08[K
  iter:  10
  ELBO:  -26.85480220115716[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:04:16[K
  iter:  20
  ELBO:  -25.465444295531924[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:04:19[K
  iter:  30
  ELBO:  -24.217839663708514[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:04:07[K
  iter:  40
  ELBO:  -23.223133523714495[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:04:15[K
  iter:  50
  ELBO:  -22.567557185060824[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Classification Error
â””   err = 0.12
Starting training Sparse Variational Gaussian Process with a Logistic-Softmax Likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 5 latent GPs
Training Progress:   2%|â–‹                               |  ETA: 0:34:40[K
  iter:  10
  ELBO:  -49.35338984675457[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:36:38[K
  iter:  20
  ELBO:  -41.16411651416668[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:38:00[K
  iter:  30
  ELBO:  -44.22525228539834[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:37:36[K
  iter:  40
  ELBO:  -43.97645560619186[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:36:05[K
  iter:  50
  ELBO:  -44.020038336192954[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Multiclass Error
â””   err = 0.15
Starting training Sparse Variational Gaussian Process with a Logistic-Softmax Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 5 latent GPs
Training Progress:   2%|â–‹                               |  ETA: 0:31:07[K
  iter:  10
  ELBO:  -36.0747705571992[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:36:33[K
  iter:  20
  ELBO:  -34.4478201922481[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:36:07[K
  iter:  30
  ELBO:  -32.80267257984208[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:34:47[K
  iter:  40
  ELBO:  -31.148706915774156[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:33:47[K
  iter:  50
  ELBO:  -29.50121146723589[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Multiclass Error
â””   err = 0.33
Starting training Sparse Variational Gaussian Process with a Poisson Likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapfoldl_impl at reduce.jl:301 [inlined]
â”” @ Core .&#x2F;reduce.jl:301
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapfoldl_impl(::typeof(SpecialFunctions.lfactorial), ::typeof(Base.add_sum), ::NamedTuple{(:init,),Tuple{Float64}}, ::SubArray{Int64,1,Array{Int64,1},Tuple{Array{Int64,1}},false}, ::Tuple{Base.OneTo{Int64},Int64}) at reduce.jl:45
â”” @ Base .&#x2F;reduce.jl:45
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapfoldl_impl(::typeof(SpecialFunctions.lfactorial), ::typeof(Base.add_sum), ::NamedTuple{(:init,),Tuple{Float64}}, ::SubArray{Int64,1,Array{Int64,1},Tuple{Array{Int64,1}},false}, ::Tuple{Base.OneTo{Int64},Int64}) at reduce.jl:49
â”” @ Base .&#x2F;reduce.jl:49
Training Progress:   2%|â–‹                               |  ETA: 0:08:03[K
  iter:  10
  ELBO:  -139.15902420996977[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:07:57[K
  iter:  20
  ELBO:  -133.03364964276952[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:08:17[K
  iter:  30
  ELBO:  -140.48091147463396[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:08:45[K
  iter:  40
  ELBO:  -144.3885844875022[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:08:51[K
  iter:  50
  ELBO:  -141.88303814571918[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 0.7510338044696269
Starting training Sparse Variational Gaussian Process with a Poisson Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:09:25[K
  iter:  10
  ELBO:  -145.46229622545312[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:10:07[K
  iter:  20
  ELBO:  -144.11699398013732[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:09:31[K
  iter:  30
  ELBO:  -142.97528946376272[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:09:25[K
  iter:  40
  ELBO:  -142.03652823774968[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:09:11[K
  iter:  50
  ELBO:  -141.27613432017748[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 0.7455536649032818
Starting training Sparse Variational Gaussian Process with a Negative Binomial Likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:09:30[K
  iter:  10
  ELBO:  -545.1836920779126[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:11:05[K
  iter:  20
  ELBO:  -431.2933407778883[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:10:51[K
  iter:  30
  ELBO:  -410.62566331071366[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:10:04[K
  iter:  40
  ELBO:  -416.3963375083516[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:09:21[K
  iter:  50
  ELBO:  -463.387603307715[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 7.459339822755598
Starting training Sparse Variational Gaussian Process with a Negative Binomial Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:06:28[K
  iter:  10
  ELBO:  -432.4950813465152[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:07:09[K
  iter:  20
  ELBO:  -421.048391009173[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:07:17[K
  iter:  30
  ELBO:  -413.58238983648727[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:07:39[K
  iter:  40
  ELBO:  -409.5425285298352[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:07:48[K
  iter:  50
  ELBO:  -408.2247063170046[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 7.530005362003821
Test Summary:                      | Pass  Total
Augmented Gaussian Process Testing |   79     79
   Testing AugmentedGaussianProcesses tests passed 
</pre>
      </div>

    <h3>Results with Julia v1.3.0</h3>

    <p>
      Testing was <strong>successful</strong>.
      Last evaluation was  ago and took 33 minutes, 9 seconds.
    </p>

    <p>
      Click <a href="/home/maleadt/Julia/pkg/NewPkgEval/site/build/logs/AugmentedGaussianProcesses/1.3.0.log">here</a> to download the log file.
      
    </p>

      <button class="collapsible">Click here to show the log contents.</button>
      <div class="content">
      <pre> Resolving package versions...
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed Ratios â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed KernelDensity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed SortingAlgorithms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed GradDescent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed DiffResults â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.0.4
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed AugmentedGaussianProcesses â”€â”€ v0.6.0
 Installed AxisAlgorithms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed DataStructures â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.17.6
 Installed LineSearches â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v7.0.1
 Installed FFTW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed LazyArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.14.10
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed KernelFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.1
 Installed FastGaussQuadrature â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.1.1
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.0
 Installed BinaryProvider â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.8
 Installed CategoricalArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.3
 Installed InvertedIndices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed Parsers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.10
 Installed MCMCChains â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.15
 Installed NLSolversBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v7.5.0
 Installed IterTools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.3.0
 Installed ProgressMeter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.2.0
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed NearestNeighbors â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.4
 Installed MacroTools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.2
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed Distributions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.21.9
 Installed TableTraits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed PositiveFactorizations â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed RangeArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed IntervalSets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.2
 Installed SpecialFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.0
 Installed ArgCheck â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.1
 Installed OrderedCollections â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed ArrayLayouts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.1.5
 Installed Showoff â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.21.0
 Installed AdvancedHMC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.14
 Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.0
 Installed CommonSubexpressions â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.0
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.10
 Installed InplaceOps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.0
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed NaNMath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.3
 Installed Tables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.11
 Installed DataValueInterfaces â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed ForwardDiff â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.10.7
 Installed DiffEqDiffTools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.5.0
 Installed DiffRules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.1.0
 Installed Optim â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.19.5
 Installed Calculus â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed Interpolations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed ArrayInterface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.0.0
 Installed VersionParsing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.3
 Installed Conda â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.3.0
 Installed Requires â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.2
 Installed IteratorInterfaceExtensions â”€ v1.0.0
 Installed OffsetArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.11.2
 Installed PooledArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.2
 Installed DataFrames â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.19.4
 Installed Reexport â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.0
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed AxisArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.3
 Installed WoodburyMatrices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed AbstractFFTs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.0
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
  Updating `~&#x2F;.julia&#x2F;environments&#x2F;v1.3&#x2F;Project.toml`
  [38eea1fd] + AugmentedGaussianProcesses v0.6.0
  Updating `~&#x2F;.julia&#x2F;environments&#x2F;v1.3&#x2F;Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [0bf59076] + AdvancedHMC v0.2.14
  [dce04be8] + ArgCheck v1.0.1
  [7d9fca2a] + Arpack v0.3.1
  [4fba245c] + ArrayInterface v2.0.0
  [4c555306] + ArrayLayouts v0.1.5
  [38eea1fd] + AugmentedGaussianProcesses v0.6.0
  [13072b0f] + AxisAlgorithms v1.0.0
  [39de3d68] + AxisArrays v0.3.3
  [9e28174c] + BinDeps v0.8.10
  [b99e7846] + BinaryProvider v0.5.8
  [49dc2e85] + Calculus v0.5.1
  [324d7699] + CategoricalArrays v0.7.3
  [aaaa29a8] + Clustering v0.13.3
  [bbf7d656] + CommonSubexpressions v0.2.0
  [34da2185] + Compat v2.2.0
  [8f4d0f93] + Conda v1.3.0
  [9a962f9c] + DataAPI v1.1.0
  [a93c6f00] + DataFrames v0.19.4
  [864edb3b] + DataStructures v0.17.6
  [e2d170a0] + DataValueInterfaces v1.0.0
  [01453d9d] + DiffEqDiffTools v1.5.0
  [163ba53b] + DiffResults v0.0.4
  [b552c78f] + DiffRules v0.1.0
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.9
  [7a1cc6ca] + FFTW v1.1.0
  [442a2c76] + FastGaussQuadrature v0.4.1
  [1a297f60] + FillArrays v0.8.2
  [f6369f11] + ForwardDiff v0.10.7
  [e1397348] + GradDescent v0.3.1
  [505f98c9] + InplaceOps v0.3.0
  [a98d9a8b] + Interpolations v0.12.5
  [8197267c] + IntervalSets v0.3.2
  [41ab1584] + InvertedIndices v1.0.0
  [c8e1da08] + IterTools v1.3.0
  [82899510] + IteratorInterfaceExtensions v1.0.0
  [682c06a0] + JSON v0.21.0
  [5ab0869b] + KernelDensity v0.5.1
  [ec8451be] + KernelFunctions v0.2.1
  [5078a376] + LazyArrays v0.14.10
  [d3d80556] + LineSearches v7.0.1
  [c7f686f2] + MCMCChains v0.3.15
  [1914dd2f] + MacroTools v0.5.2
  [e1d29d7a] + Missings v0.4.3
  [d41bc354] + NLSolversBase v7.5.0
  [77ba4419] + NaNMath v0.3.3
  [b8a86587] + NearestNeighbors v0.4.4
  [6fe1bfb0] + OffsetArrays v0.11.2
  [429524aa] + Optim v0.19.5
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [69de0a69] + Parsers v0.3.10
  [2dfb63ee] + PooledArrays v0.5.2
  [85a6dd25] + PositiveFactorizations v0.2.3
  [92933f4c] + ProgressMeter v1.2.0
  [1fd47b50] + QuadGK v2.1.1
  [b3c3ace0] + RangeArrays v0.3.1
  [c84ed2f1] + Ratios v0.3.1
  [3cdcf5f2] + RecipesBase v0.7.0
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v0.5.2
  [79098fc4] + Rmath v0.6.0
  [992d4aef] + Showoff v0.3.1
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.8.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.8.0
  [3783bdb8] + TableTraits v1.0.0
  [bd369af6] + Tables v0.2.11
  [30578b45] + URIParser v0.4.0
  [81def892] + VersionParsing v1.1.3
  [efce3f68] + WoodburyMatrices v0.4.1
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [9fa8497b] + Future 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~&#x2F;.julia&#x2F;packages&#x2F;Arpack&#x2F;cu5By&#x2F;deps&#x2F;build.log`
  Building Conda â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~&#x2F;.julia&#x2F;packages&#x2F;Conda&#x2F;kLXeC&#x2F;deps&#x2F;build.log`
  Building FFTW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~&#x2F;.julia&#x2F;packages&#x2F;FFTW&#x2F;loJ3F&#x2F;deps&#x2F;build.log`
  Building Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~&#x2F;.julia&#x2F;packages&#x2F;Rmath&#x2F;BoBag&#x2F;deps&#x2F;build.log`
  Building SpecialFunctions â†’ `~&#x2F;.julia&#x2F;packages&#x2F;SpecialFunctions&#x2F;ne2iw&#x2F;deps&#x2F;build.log`
   Testing AugmentedGaussianProcesses
 Resolving package versions...
    Status `&#x2F;tmp&#x2F;jl_ngP2ob&#x2F;Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [0bf59076] AdvancedHMC v0.2.14
  [dce04be8] ArgCheck v1.0.1
  [7d9fca2a] Arpack v0.3.1
  [4fba245c] ArrayInterface v2.0.0
  [4c555306] ArrayLayouts v0.1.5
  [38eea1fd] AugmentedGaussianProcesses v0.6.0
  [13072b0f] AxisAlgorithms v1.0.0
  [39de3d68] AxisArrays v0.3.3
  [9e28174c] BinDeps v0.8.10
  [b99e7846] BinaryProvider v0.5.8
  [49dc2e85] Calculus v0.5.1
  [324d7699] CategoricalArrays v0.7.3
  [aaaa29a8] Clustering v0.13.3
  [bbf7d656] CommonSubexpressions v0.2.0
  [34da2185] Compat v2.2.0
  [8f4d0f93] Conda v1.3.0
  [9a962f9c] DataAPI v1.1.0
  [a93c6f00] DataFrames v0.19.4
  [864edb3b] DataStructures v0.17.6
  [e2d170a0] DataValueInterfaces v1.0.0
  [01453d9d] DiffEqDiffTools v1.5.0
  [163ba53b] DiffResults v0.0.4
  [b552c78f] DiffRules v0.1.0
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.9
  [7a1cc6ca] FFTW v1.1.0
  [442a2c76] FastGaussQuadrature v0.4.1
  [1a297f60] FillArrays v0.8.2
  [f6369f11] ForwardDiff v0.10.7
  [e1397348] GradDescent v0.3.1
  [505f98c9] InplaceOps v0.3.0
  [a98d9a8b] Interpolations v0.12.5
  [8197267c] IntervalSets v0.3.2
  [41ab1584] InvertedIndices v1.0.0
  [c8e1da08] IterTools v1.3.0
  [82899510] IteratorInterfaceExtensions v1.0.0
  [682c06a0] JSON v0.21.0
  [5ab0869b] KernelDensity v0.5.1
  [ec8451be] KernelFunctions v0.2.1
  [5078a376] LazyArrays v0.14.10
  [d3d80556] LineSearches v7.0.1
  [c7f686f2] MCMCChains v0.3.15
  [1914dd2f] MacroTools v0.5.2
  [e1d29d7a] Missings v0.4.3
  [d41bc354] NLSolversBase v7.5.0
  [77ba4419] NaNMath v0.3.3
  [b8a86587] NearestNeighbors v0.4.4
  [6fe1bfb0] OffsetArrays v0.11.2
  [429524aa] Optim v0.19.5
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [69de0a69] Parsers v0.3.10
  [2dfb63ee] PooledArrays v0.5.2
  [85a6dd25] PositiveFactorizations v0.2.3
  [92933f4c] ProgressMeter v1.2.0
  [1fd47b50] QuadGK v2.1.1
  [b3c3ace0] RangeArrays v0.3.1
  [c84ed2f1] Ratios v0.3.1
  [3cdcf5f2] RecipesBase v0.7.0
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v0.5.2
  [79098fc4] Rmath v0.6.0
  [992d4aef] Showoff v0.3.1
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.8.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.8.0
  [3783bdb8] TableTraits v1.0.0
  [bd369af6] Tables v0.2.11
  [30578b45] URIParser v0.4.0
  [81def892] VersionParsing v1.1.3
  [efce3f68] WoodburyMatrices v0.4.1
  [2a0f44e3] Base64  [`@stdlib&#x2F;Base64`]
  [ade2ca70] Dates  [`@stdlib&#x2F;Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib&#x2F;DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib&#x2F;Distributed`]
  [9fa8497b] Future  [`@stdlib&#x2F;Future`]
  [b77e0a4c] InteractiveUtils  [`@stdlib&#x2F;InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib&#x2F;LibGit2`]
  [8f399da3] Libdl  [`@stdlib&#x2F;Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib&#x2F;LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib&#x2F;Logging`]
  [d6f4376e] Markdown  [`@stdlib&#x2F;Markdown`]
  [a63ad114] Mmap  [`@stdlib&#x2F;Mmap`]
  [44cfe95a] Pkg  [`@stdlib&#x2F;Pkg`]
  [de0858da] Printf  [`@stdlib&#x2F;Printf`]
  [3fa0cd96] REPL  [`@stdlib&#x2F;REPL`]
  [9a3f8284] Random  [`@stdlib&#x2F;Random`]
  [ea8e919c] SHA  [`@stdlib&#x2F;SHA`]
  [9e88b42a] Serialization  [`@stdlib&#x2F;Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib&#x2F;SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib&#x2F;Sockets`]
  [2f01184e] SparseArrays  [`@stdlib&#x2F;SparseArrays`]
  [10745b16] Statistics  [`@stdlib&#x2F;Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib&#x2F;SuiteSparse`]
  [8dfed614] Test  [`@stdlib&#x2F;Test`]
  [cf7118a7] UUIDs  [`@stdlib&#x2F;UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib&#x2F;Unicode`]
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lstirling_asym(::BigFloat) at misc.jl:56
â”” @ StatsFuns ~&#x2F;.julia&#x2F;packages&#x2F;StatsFuns&#x2F;2QE7p&#x2F;src&#x2F;misc.jl:56
WARNING: Method definition deepcopy(GradDescent.Optimizer) in module GradDescent at &#x2F;root&#x2F;.julia&#x2F;packages&#x2F;GradDescent&#x2F;C4qjb&#x2F;src&#x2F;AbstractOptimizer.jl:22 overwritten in module AugmentedGaussianProcesses at &#x2F;root&#x2F;.julia&#x2F;packages&#x2F;AugmentedGaussianProcesses&#x2F;8kAgJ&#x2F;src&#x2F;functions&#x2F;utils.jl:71.
  ** incremental compilation may be fatally broken for this module **

Starting training Gaussian Process with a Gaussian likelihood infered by Analytic Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:07:05[K
  iter:  10
  ELBO:  624.055311605656[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:03:55[K
  iter:  20
  ELBO:  635.674952676726[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:02:57[K
  iter:  30
  ELBO:  589.8717573550398[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:02:15[K
  iter:  40
  ELBO:  662.1781749152855[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:01:49[K
  iter:  50
  ELBO:  623.4231417439881[A[ATraining ended after 50 iterations. Total number of iterations 50
Starting training Variational Gaussian Process with a Student-t likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:26:20[K
  iter:  10
  ELBO:  -152.22527095522128[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:17:16[K
  iter:  20
  ELBO:  -150.83076430626713[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:12:26[K
  iter:  30
  ELBO:  -149.87410204825002[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:10:33[K
  iter:  40
  ELBO:  -149.3256010303905[A[ATraining ended after 50 iterations. Total number of iterations 50


[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:09:13[K
  iter:  50
  ELBO:  -149.09330240808055[A[Aâ”Œ Info: Regression Error
â””   err = 0.4242331022347892
Starting training Variational Gaussian Process with a Laplace likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:09:35[K
  iter:  10
  ELBO:  -566.225785866745[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:08:45[K
  iter:  20
  ELBO:  -568.6837211638668[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:08:47[K
  iter:  30
  ELBO:  -570.2704750617578[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:08:45[K
  iter:  40
  ELBO:  -571.5108565720788[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:08:33[K
  iter:  50
  ELBO:  -572.6758898614879[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.4018312504927594
Starting training Variational Gaussian Process with a Gaussian likelihood with heteroscedastic noise infered by Analytic Variational Inference  with 100 samples with 2 features and 2 latent GPs
Training Progress:   2%|â–‹                               |  ETA: 0:17:16[K
  iter:  10
  ELBO:  -151.91804200759827[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:19:20[K
  iter:  20
  ELBO:  -148.2628097629236[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:19:22[K
  iter:  30
  ELBO:  -145.8411732543865[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:17:34[K
  iter:  40
  ELBO:  -143.96603507455967[A[ATraining ended after 50 iterations. Total number of iterations 50


[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:16:03[K
  iter:  50
  ELBO:  -142.6234705895817[A[Aâ”Œ Info: Regression Error
â””   err = 0.6697049944690828
Starting training Variational Gaussian Process with a Bayesian SVM infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:07:50[K
  iter:  10
  ELBO:  69.36594915002166[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:06:27[K
  iter:  20
  ELBO:  81.76959815148342[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:06:42[K
  iter:  30
  ELBO:  93.11305693561144[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:07:34[K
  iter:  40
  ELBO:  102.88460405829255[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:07:30[K
  iter:  50
  ELBO:  111.76775053363693[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Classification Error
â””   err = 0.02
Starting training Variational Gaussian Process with a Bernoulli Likelihood with Logistic Link infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:10:30[K
  iter:  10
  ELBO:  -15.45496403516649[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:08:17[K
  iter:  20
  ELBO:  -12.921811247704284[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:08:17[K
  iter:  30
  ELBO:  -10.525979508342859[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:07:43[K
  iter:  40
  ELBO:  -8.358200907239684[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:06:48[K
  iter:  50
  ELBO:  -6.4397859300417934[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Classification Error
â””   err = 0.06
Starting training Variational Gaussian Process with a Logistic-Softmax Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 5 latent GPs
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = mapreduce_impl(::typeof(SpecialFunctions.lgamma), ::typeof(Base.add_sum), ::Array{Float64,1}, ::Int64, ::Int64, ::Int64) at reduce.jl:155
â”” @ Base .&#x2F;reduce.jl:155
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = mapreduce_impl(::typeof(SpecialFunctions.lgamma), ::typeof(Base.add_sum), ::Array{Float64,1}, ::Int64, ::Int64, ::Int64) at reduce.jl:155
â”” @ Base .&#x2F;reduce.jl:155
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = macro expansion at reduce.jl:158 [inlined]
â”” @ Core .&#x2F;reduce.jl:158
Training Progress:   2%|â–‹                               |  ETA: 0:29:25[K
  iter:  10
  ELBO:  -35.3935785497838[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:29:46[K
  iter:  20
  ELBO:  -34.450206095421095[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:31:38[K
  iter:  30
  ELBO:  -33.48761577222891[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:31:57[K
  iter:  40
  ELBO:  -32.511984642637856[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:31:56[K
  iter:  50
  ELBO:  -31.53238843149282[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Multiclass Error
â””   err = 0.27
Starting training Variational Gaussian Process with a Poisson Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapreduce_impl(::typeof(SpecialFunctions.lfactorial), ::typeof(Base.add_sum), ::SubArray{Int64,1,Array{Int64,1},Tuple{UnitRange{Int64}},true}, ::Int64, ::Int64, ::Int64) at reduce.jl:155
â”” @ Base .&#x2F;reduce.jl:155
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapreduce_impl(::typeof(SpecialFunctions.lfactorial), ::typeof(Base.add_sum), ::SubArray{Int64,1,Array{Int64,1},Tuple{UnitRange{Int64}},true}, ::Int64, ::Int64, ::Int64) at reduce.jl:155
â”” @ Base .&#x2F;reduce.jl:155
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = macro expansion at reduce.jl:158 [inlined]
â”” @ Core .&#x2F;reduce.jl:158
Training Progress:   2%|â–‹                               |  ETA: 0:08:58[K
  iter:  10
  ELBO:  -127.88298349900538[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:09:26[K
  iter:  20
  ELBO:  -127.29460423970174[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:08:11[K
  iter:  30
  ELBO:  -126.78849653826994[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:07:40[K
  iter:  40
  ELBO:  -126.35342619265279[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:06:34[K
  iter:  50
  ELBO:  -125.97784291753513[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 0.7098173135397451
Starting training Variational Gaussian Process with a Negative Binomial Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:07:30[K
  iter:  10
  ELBO:  -721.0880180049668[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:06:41[K
  iter:  20
  ELBO:  -722.0593597319065[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:06:34[K
  iter:  30
  ELBO:  -724.9942368244377[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:06:28[K
  iter:  40
  ELBO:  -729.9041714833297[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:07:01[K
  iter:  50
  ELBO:  -736.0449100226631[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 17.843017416604514
Starting training Sparse Variational Gaussian Process with a Gaussian likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:18:01[K
  iter:  10
  ELBO:  -17079.797227277842[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:13:14[K
  iter:  20
  ELBO:  -8599.597977234811[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:11:09[K
  iter:  30
  ELBO:  -5242.010884223601[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:09:57[K
  iter:  40
  ELBO:  -3289.1278946429925[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:08:14[K
  iter:  50
  ELBO:  -2128.361384061914[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.19166431205933365
Starting training Sparse Variational Gaussian Process with a Gaussian likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:10:42[K
  iter:  10
  ELBO:  -9899.639904103531[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:09:42[K
  iter:  20
  ELBO:  -5426.539173392311[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:07:02[K
  iter:  30
  ELBO:  -2843.9384952479813[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:04:32[K
  iter:  50
  ELBO:  -1244.9903501916276[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.19240798383401675
Starting training Sparse Variational Gaussian Process with a Student-t likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:06:36[K
  iter:  10
  ELBO:  -154.46487995526215[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:05:09[K
  iter:  20
  ELBO:  -154.20442389905529[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:03:56[K
  iter:  30
  ELBO:  -148.27646371341282[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:03:32[K
  iter:  40
  ELBO:  -144.721419278619[A[A

Training ended after 50 iterations. Total number of iterations 50
[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:03:14[K
  iter:  50
  ELBO:  -149.6070600895724[A[Aâ”Œ Info: Regression Error
â””   err = 0.37437043455267
Starting training Sparse Variational Gaussian Process with a Student-t likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:00:15[K
  iter:  10
  ELBO:  -153.04344847573242[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:00:21[K
  iter:  20
  ELBO:  -149.99639403772224[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:01:49[K
  iter:  30
  ELBO:  -147.7602417610451[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:02:41[K
  iter:  40
  ELBO:  -146.24357901950046[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:03:06[K
  iter:  50
  ELBO:  -145.29013276252704[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.41590173469563896
Starting training Sparse Variational Gaussian Process with a Laplace likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:06:45[K
  iter:  10
  ELBO:  -484.54426228743625[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:07:00[K
  iter:  20
  ELBO:  -508.1824957786268[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:06:14[K
  iter:  30
  ELBO:  -529.6422203331739[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:06:29[K
  iter:  40
  ELBO:  -535.1785651152693[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:06:14[K
  iter:  50
  ELBO:  -539.2752458689331[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.36679289894619643
Starting training Sparse Variational Gaussian Process with a Laplace likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:03:14[K
  iter:  10
  ELBO:  -532.2261019516801[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:03:05[K
  iter:  20
  ELBO:  -541.9117945690705[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:03:58[K
  iter:  30
  ELBO:  -550.4257458267432[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:04:31[K
  iter:  40
  ELBO:  -557.2638921738726[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:05:10[K
  iter:  50
  ELBO:  -562.3300006862518[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.4045807937532465
Starting training Sparse Variational Gaussian Process with a Bayesian SVM infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:05:10[K
  iter:  10
  ELBO:  65.9218130002265[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:05:06[K
  iter:  20
  ELBO:  76.82715598619467[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:03:50[K
  iter:  30
  ELBO:  73.98349532366115[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:03:05[K
  iter:  40
  ELBO:  74.00915532136801[A[ATraining ended after 50 iterations. Total number of iterations 50


[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:03:10[K
  iter:  50
  ELBO:  97.50413919760484[A[Aâ”Œ Info: Classification Error
â””   err = 0.08
Starting training Sparse Variational Gaussian Process with a Bayesian SVM infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:04:11[K
  iter:  10
  ELBO:  68.98355584076893[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:05:04[K
  iter:  20
  ELBO:  76.78745658806402[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:05:39[K
  iter:  30
  ELBO:  84.52423904711736[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:05:53[K
  iter:  40
  ELBO:  92.2066783805736[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:06:18[K
  iter:  50
  ELBO:  99.92516828116736[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Classification Error
â””   err = 0.1
Starting training Sparse Variational Gaussian Process with a Bernoulli Likelihood with Logistic Link infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:06:33[K
  iter:  10
  ELBO:  -27.751042546926456[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:05:28[K
  iter:  20
  ELBO:  -28.644634401176216[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:06:00[K
  iter:  30
  ELBO:  -27.546234465921838[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:05:59[K
  iter:  40
  ELBO:  -30.514751102705365[A[ATraining ended after 50 iterations. Total number of iterations 50


[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:05:42[K
  iter:  50
  ELBO:  -24.39375109216409[A[Aâ”Œ Info: Classification Error
â””   err = 0.09
Starting training Sparse Variational Gaussian Process with a Bernoulli Likelihood with Logistic Link infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:04:27[K
  iter:  10
  ELBO:  -26.85480220115716[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:03:48[K
  iter:  20
  ELBO:  -25.465444295531924[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:04:17[K
  iter:  30
  ELBO:  -24.217839663708514[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:04:54[K
  iter:  40
  ELBO:  -23.223133523714495[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:05:11[K
  iter:  50
  ELBO:  -22.567557185060824[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Classification Error
â””   err = 0.12
Starting training Sparse Variational Gaussian Process with a Logistic-Softmax Likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 5 latent GPs
Training Progress:   2%|â–‹                               |  ETA: 0:33:10[K
  iter:  10
  ELBO:  -49.35338984675457[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:25:16[K
  iter:  20
  ELBO:  -41.16411651416668[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:27:06[K
  iter:  30
  ELBO:  -44.22525228539834[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:26:17[K
  iter:  40
  ELBO:  -43.97645560619186[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:25:56[K
  iter:  50
  ELBO:  -44.020038336192954[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Multiclass Error
â””   err = 0.15
Starting training Sparse Variational Gaussian Process with a Logistic-Softmax Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 5 latent GPs
Training Progress:   2%|â–‹                               |  ETA: 0:26:00[K
  iter:  10
  ELBO:  -36.0747705571992[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:31:51[K
  iter:  20
  ELBO:  -34.4478201922481[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:33:57[K
  iter:  30
  ELBO:  -32.80267257984208[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:29:39[K
  iter:  40
  ELBO:  -31.148706915774156[A[ATraining ended after 50 iterations. Total number of iterations 50


[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:27:13[K
  iter:  50
  ELBO:  -29.50121146723589[A[Aâ”Œ Info: Multiclass Error
â””   err = 0.33
Starting training Sparse Variational Gaussian Process with a Poisson Likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapreduce_first at reduce.jl:293 [inlined]
â”” @ Core .&#x2F;reduce.jl:293
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapfoldl_impl(::typeof(SpecialFunctions.lfactorial), ::typeof(Base.add_sum), ::NamedTuple{(:init,),Tuple{Float64}}, ::SubArray{Int64,1,Array{Int64,1},Tuple{Array{Int64,1}},false}, ::Tuple{Base.OneTo{Int64},Int64}) at reduce.jl:45
â”” @ Base .&#x2F;reduce.jl:45
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapfoldl_impl(::typeof(SpecialFunctions.lfactorial), ::typeof(Base.add_sum), ::NamedTuple{(:init,),Tuple{Float64}}, ::SubArray{Int64,1,Array{Int64,1},Tuple{Array{Int64,1}},false}, ::Tuple{Base.OneTo{Int64},Int64}) at reduce.jl:49
â”” @ Base .&#x2F;reduce.jl:49
Training Progress:   2%|â–‹                               |  ETA: 0:06:38[K
  iter:  10
  ELBO:  -139.15902420996977[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:06:51[K
  iter:  20
  ELBO:  -133.03364964276952[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:07:07[K
  iter:  30
  ELBO:  -140.48091147463396[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:05:59[K
  iter:  40
  ELBO:  -144.3885844875022[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:05:33[K
  iter:  50
  ELBO:  -141.88303814571918[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 0.7510338044696269
Starting training Sparse Variational Gaussian Process with a Poisson Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:04:45[K
  iter:  10
  ELBO:  -145.46229622545312[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:05:03[K
  iter:  20
  ELBO:  -144.11699398013732[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:05:06[K
  iter:  30
  ELBO:  -142.97528946376272[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:04:49[K
  iter:  40
  ELBO:  -142.03652823774968[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:04:37[K
  iter:  50
  ELBO:  -141.27613432017748[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 0.7455536649032818
Starting training Sparse Variational Gaussian Process with a Negative Binomial Likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:06:49[K
  iter:  10
  ELBO:  -545.1836920779126[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:06:29[K
  iter:  20
  ELBO:  -431.2933407778883[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:05:49[K
  iter:  30
  ELBO:  -410.62566331071366[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:05:40[K
  iter:  40
  ELBO:  -416.3963375083516[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:05:28[K
  iter:  50
  ELBO:  -463.387603307715[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 7.459339822755598
Starting training Sparse Variational Gaussian Process with a Negative Binomial Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:05:31[K
  iter:  10
  ELBO:  -432.4950813465152[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:06:36[K
  iter:  20
  ELBO:  -421.048391009173[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:05:38[K
  iter:  30
  ELBO:  -413.58238983648727[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:05:30[K
  iter:  40
  ELBO:  -409.5425285298352[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:05:21[K
  iter:  50
  ELBO:  -408.2247063170046[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 7.530005362003821
Test Summary:                      | Pass  Total
Augmented Gaussian Process Testing |   79     79
   Testing AugmentedGaussianProcesses tests passed 
</pre>
      </div>

    <h3>Results with Julia v1.3.1-pre-7704df0a5a</h3>

    <p>
      Testing was <strong>successful</strong>.
      Last evaluation was  ago and took 34 minutes, 4 seconds.
    </p>

    <p>
      Click <a href="/home/maleadt/Julia/pkg/NewPkgEval/site/build/logs/AugmentedGaussianProcesses/1.3.1-pre-7704df0a5a.log">here</a> to download the log file.
      
    </p>

      <button class="collapsible">Click here to show the log contents.</button>
      <div class="content">
      <pre> Resolving package versions...
 Installed Ratios â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed FastGaussQuadrature â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed Conda â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.3.0
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.1.1
 Installed DataStructures â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.17.6
 Installed KernelFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.1
 Installed AugmentedGaussianProcesses â”€â”€ v0.6.0
 Installed Optim â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.19.5
 Installed NaNMath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.3
 Installed ArrayLayouts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.1.5
 Installed SpecialFunctions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.0
 Installed LazyArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.14.10
 Installed Tables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.11
 Installed DataFrames â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.19.4
 Installed ArgCheck â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.1
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed DiffResults â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.0.4
 Installed Showoff â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.10
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed IterTools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.3.0
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed MacroTools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.2
 Installed ForwardDiff â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.10.7
 Installed AxisAlgorithms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed LineSearches â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v7.0.1
 Installed OffsetArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.11.2
 Installed Calculus â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed FFTW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed AxisArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.3
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed TableTraits â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed AdvancedHMC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.14
 Installed CommonSubexpressions â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.0
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.0
 Installed BinaryProvider â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.8
 Installed PooledArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.2
 Installed GradDescent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed ProgressMeter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.2.0
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed InplaceOps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.0
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed NLSolversBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v7.5.0
 Installed InvertedIndices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed Requires â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.2
 Installed DiffRules â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.1.0
 Installed Interpolations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed IntervalSets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.2
 Installed ArrayInterface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.0.0
 Installed AbstractFFTs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.0
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed PositiveFactorizations â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed KernelDensity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed DataValueInterfaces â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed Distributions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.21.9
 Installed Reexport â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.2.0
 Installed CategoricalArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.3
 Installed RangeArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.0
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
 Installed IteratorInterfaceExtensions â”€ v1.0.0
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed WoodburyMatrices â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed OrderedCollections â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed MCMCChains â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.15
 Installed NearestNeighbors â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.4
 Installed JSON â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.21.0
 Installed Parsers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.10
 Installed VersionParsing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.3
 Installed SortingAlgorithms â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.3.1
 Installed DiffEqDiffTools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.5.0
  Updating `~&#x2F;.julia&#x2F;environments&#x2F;v1.3&#x2F;Project.toml`
  [38eea1fd] + AugmentedGaussianProcesses v0.6.0
  Updating `~&#x2F;.julia&#x2F;environments&#x2F;v1.3&#x2F;Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [0bf59076] + AdvancedHMC v0.2.14
  [dce04be8] + ArgCheck v1.0.1
  [7d9fca2a] + Arpack v0.3.1
  [4fba245c] + ArrayInterface v2.0.0
  [4c555306] + ArrayLayouts v0.1.5
  [38eea1fd] + AugmentedGaussianProcesses v0.6.0
  [13072b0f] + AxisAlgorithms v1.0.0
  [39de3d68] + AxisArrays v0.3.3
  [9e28174c] + BinDeps v0.8.10
  [b99e7846] + BinaryProvider v0.5.8
  [49dc2e85] + Calculus v0.5.1
  [324d7699] + CategoricalArrays v0.7.3
  [aaaa29a8] + Clustering v0.13.3
  [bbf7d656] + CommonSubexpressions v0.2.0
  [34da2185] + Compat v2.2.0
  [8f4d0f93] + Conda v1.3.0
  [9a962f9c] + DataAPI v1.1.0
  [a93c6f00] + DataFrames v0.19.4
  [864edb3b] + DataStructures v0.17.6
  [e2d170a0] + DataValueInterfaces v1.0.0
  [01453d9d] + DiffEqDiffTools v1.5.0
  [163ba53b] + DiffResults v0.0.4
  [b552c78f] + DiffRules v0.1.0
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.9
  [7a1cc6ca] + FFTW v1.1.0
  [442a2c76] + FastGaussQuadrature v0.4.1
  [1a297f60] + FillArrays v0.8.2
  [f6369f11] + ForwardDiff v0.10.7
  [e1397348] + GradDescent v0.3.1
  [505f98c9] + InplaceOps v0.3.0
  [a98d9a8b] + Interpolations v0.12.5
  [8197267c] + IntervalSets v0.3.2
  [41ab1584] + InvertedIndices v1.0.0
  [c8e1da08] + IterTools v1.3.0
  [82899510] + IteratorInterfaceExtensions v1.0.0
  [682c06a0] + JSON v0.21.0
  [5ab0869b] + KernelDensity v0.5.1
  [ec8451be] + KernelFunctions v0.2.1
  [5078a376] + LazyArrays v0.14.10
  [d3d80556] + LineSearches v7.0.1
  [c7f686f2] + MCMCChains v0.3.15
  [1914dd2f] + MacroTools v0.5.2
  [e1d29d7a] + Missings v0.4.3
  [d41bc354] + NLSolversBase v7.5.0
  [77ba4419] + NaNMath v0.3.3
  [b8a86587] + NearestNeighbors v0.4.4
  [6fe1bfb0] + OffsetArrays v0.11.2
  [429524aa] + Optim v0.19.5
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [69de0a69] + Parsers v0.3.10
  [2dfb63ee] + PooledArrays v0.5.2
  [85a6dd25] + PositiveFactorizations v0.2.3
  [92933f4c] + ProgressMeter v1.2.0
  [1fd47b50] + QuadGK v2.1.1
  [b3c3ace0] + RangeArrays v0.3.1
  [c84ed2f1] + Ratios v0.3.1
  [3cdcf5f2] + RecipesBase v0.7.0
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v0.5.2
  [79098fc4] + Rmath v0.6.0
  [992d4aef] + Showoff v0.3.1
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.8.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.8.0
  [3783bdb8] + TableTraits v1.0.0
  [bd369af6] + Tables v0.2.11
  [30578b45] + URIParser v0.4.0
  [81def892] + VersionParsing v1.1.3
  [efce3f68] + WoodburyMatrices v0.4.1
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [9fa8497b] + Future 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Conda â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~&#x2F;.julia&#x2F;packages&#x2F;Conda&#x2F;kLXeC&#x2F;deps&#x2F;build.log`
  Building SpecialFunctions â†’ `~&#x2F;.julia&#x2F;packages&#x2F;SpecialFunctions&#x2F;ne2iw&#x2F;deps&#x2F;build.log`
  Building Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~&#x2F;.julia&#x2F;packages&#x2F;Arpack&#x2F;cu5By&#x2F;deps&#x2F;build.log`
  Building FFTW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~&#x2F;.julia&#x2F;packages&#x2F;FFTW&#x2F;loJ3F&#x2F;deps&#x2F;build.log`
  Building Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ `~&#x2F;.julia&#x2F;packages&#x2F;Rmath&#x2F;BoBag&#x2F;deps&#x2F;build.log`
   Testing AugmentedGaussianProcesses
 Resolving package versions...
    Status `&#x2F;tmp&#x2F;jl_xnv7AD&#x2F;Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [0bf59076] AdvancedHMC v0.2.14
  [dce04be8] ArgCheck v1.0.1
  [7d9fca2a] Arpack v0.3.1
  [4fba245c] ArrayInterface v2.0.0
  [4c555306] ArrayLayouts v0.1.5
  [38eea1fd] AugmentedGaussianProcesses v0.6.0
  [13072b0f] AxisAlgorithms v1.0.0
  [39de3d68] AxisArrays v0.3.3
  [9e28174c] BinDeps v0.8.10
  [b99e7846] BinaryProvider v0.5.8
  [49dc2e85] Calculus v0.5.1
  [324d7699] CategoricalArrays v0.7.3
  [aaaa29a8] Clustering v0.13.3
  [bbf7d656] CommonSubexpressions v0.2.0
  [34da2185] Compat v2.2.0
  [8f4d0f93] Conda v1.3.0
  [9a962f9c] DataAPI v1.1.0
  [a93c6f00] DataFrames v0.19.4
  [864edb3b] DataStructures v0.17.6
  [e2d170a0] DataValueInterfaces v1.0.0
  [01453d9d] DiffEqDiffTools v1.5.0
  [163ba53b] DiffResults v0.0.4
  [b552c78f] DiffRules v0.1.0
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.9
  [7a1cc6ca] FFTW v1.1.0
  [442a2c76] FastGaussQuadrature v0.4.1
  [1a297f60] FillArrays v0.8.2
  [f6369f11] ForwardDiff v0.10.7
  [e1397348] GradDescent v0.3.1
  [505f98c9] InplaceOps v0.3.0
  [a98d9a8b] Interpolations v0.12.5
  [8197267c] IntervalSets v0.3.2
  [41ab1584] InvertedIndices v1.0.0
  [c8e1da08] IterTools v1.3.0
  [82899510] IteratorInterfaceExtensions v1.0.0
  [682c06a0] JSON v0.21.0
  [5ab0869b] KernelDensity v0.5.1
  [ec8451be] KernelFunctions v0.2.1
  [5078a376] LazyArrays v0.14.10
  [d3d80556] LineSearches v7.0.1
  [c7f686f2] MCMCChains v0.3.15
  [1914dd2f] MacroTools v0.5.2
  [e1d29d7a] Missings v0.4.3
  [d41bc354] NLSolversBase v7.5.0
  [77ba4419] NaNMath v0.3.3
  [b8a86587] NearestNeighbors v0.4.4
  [6fe1bfb0] OffsetArrays v0.11.2
  [429524aa] Optim v0.19.5
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [69de0a69] Parsers v0.3.10
  [2dfb63ee] PooledArrays v0.5.2
  [85a6dd25] PositiveFactorizations v0.2.3
  [92933f4c] ProgressMeter v1.2.0
  [1fd47b50] QuadGK v2.1.1
  [b3c3ace0] RangeArrays v0.3.1
  [c84ed2f1] Ratios v0.3.1
  [3cdcf5f2] RecipesBase v0.7.0
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v0.5.2
  [79098fc4] Rmath v0.6.0
  [992d4aef] Showoff v0.3.1
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.8.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.8.0
  [3783bdb8] TableTraits v1.0.0
  [bd369af6] Tables v0.2.11
  [30578b45] URIParser v0.4.0
  [81def892] VersionParsing v1.1.3
  [efce3f68] WoodburyMatrices v0.4.1
  [2a0f44e3] Base64  [`@stdlib&#x2F;Base64`]
  [ade2ca70] Dates  [`@stdlib&#x2F;Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib&#x2F;DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib&#x2F;Distributed`]
  [9fa8497b] Future  [`@stdlib&#x2F;Future`]
  [b77e0a4c] InteractiveUtils  [`@stdlib&#x2F;InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib&#x2F;LibGit2`]
  [8f399da3] Libdl  [`@stdlib&#x2F;Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib&#x2F;LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib&#x2F;Logging`]
  [d6f4376e] Markdown  [`@stdlib&#x2F;Markdown`]
  [a63ad114] Mmap  [`@stdlib&#x2F;Mmap`]
  [44cfe95a] Pkg  [`@stdlib&#x2F;Pkg`]
  [de0858da] Printf  [`@stdlib&#x2F;Printf`]
  [3fa0cd96] REPL  [`@stdlib&#x2F;REPL`]
  [9a3f8284] Random  [`@stdlib&#x2F;Random`]
  [ea8e919c] SHA  [`@stdlib&#x2F;SHA`]
  [9e88b42a] Serialization  [`@stdlib&#x2F;Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib&#x2F;SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib&#x2F;Sockets`]
  [2f01184e] SparseArrays  [`@stdlib&#x2F;SparseArrays`]
  [10745b16] Statistics  [`@stdlib&#x2F;Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib&#x2F;SuiteSparse`]
  [8dfed614] Test  [`@stdlib&#x2F;Test`]
  [cf7118a7] UUIDs  [`@stdlib&#x2F;UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib&#x2F;Unicode`]
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lstirling_asym(::BigFloat) at misc.jl:56
â”” @ StatsFuns ~&#x2F;.julia&#x2F;packages&#x2F;StatsFuns&#x2F;2QE7p&#x2F;src&#x2F;misc.jl:56
WARNING: Method definition deepcopy(GradDescent.Optimizer) in module GradDescent at &#x2F;root&#x2F;.julia&#x2F;packages&#x2F;GradDescent&#x2F;C4qjb&#x2F;src&#x2F;AbstractOptimizer.jl:22 overwritten in module AugmentedGaussianProcesses at &#x2F;root&#x2F;.julia&#x2F;packages&#x2F;AugmentedGaussianProcesses&#x2F;8kAgJ&#x2F;src&#x2F;functions&#x2F;utils.jl:71.
  ** incremental compilation may be fatally broken for this module **

Starting training Gaussian Process with a Gaussian likelihood infered by Analytic Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:12:25[K
  iter:  10
  ELBO:  624.055311605656[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:06:59[K
  iter:  20
  ELBO:  635.674952676726[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:05:11[K
  iter:  30
  ELBO:  589.8717573550398[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:04:20[K
  iter:  40
  ELBO:  662.1781749152855[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:03:47[K
  iter:  50
  ELBO:  623.4231417439881[A[ATraining ended after 50 iterations. Total number of iterations 50
Starting training Variational Gaussian Process with a Student-t likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:29:56[K
  iter:  10
  ELBO:  -152.22527095522128[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:20:22[K
  iter:  20
  ELBO:  -150.83076430626713[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:18:36[K
  iter:  30
  ELBO:  -149.87410204825002[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:17:23[K
  iter:  40
  ELBO:  -149.3256010303905[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:15:34[K
  iter:  50
  ELBO:  -149.09330240808055[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.4242331022347892
Starting training Variational Gaussian Process with a Laplace likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:07:52[K
  iter:  10
  ELBO:  -566.225785866745[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:09:04[K
  iter:  20
  ELBO:  -568.6837211638668[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:07:45[K
  iter:  30
  ELBO:  -570.2704750617578[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:07:13[K
  iter:  40
  ELBO:  -571.5108565720788[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:06:29[K
  iter:  50
  ELBO:  -572.6758898614879[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.4018312504927594
Starting training Variational Gaussian Process with a Gaussian likelihood with heteroscedastic noise infered by Analytic Variational Inference  with 100 samples with 2 features and 2 latent GPs
Training Progress:   2%|â–‹                               |  ETA: 0:19:05[K
  iter:  10
  ELBO:  -151.91804200759827[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:16:54[K
  iter:  20
  ELBO:  -148.2628097629236[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:17:23[K
  iter:  30
  ELBO:  -145.8411732543865[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:15:44[K
  iter:  40
  ELBO:  -143.96603507455967[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:14:34[K
  iter:  50
  ELBO:  -142.6234705895817[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.6697049944690828
Starting training Variational Gaussian Process with a Bayesian SVM infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:10:26[K
  iter:  10
  ELBO:  69.36594915002166[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:09:45[K
  iter:  20
  ELBO:  81.76959815148342[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:07:39[K
  iter:  30
  ELBO:  93.11305693561144[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:07:20[K
  iter:  40
  ELBO:  102.88460405829255[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:07:18[K
  iter:  50
  ELBO:  111.76775053363693[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Classification Error
â””   err = 0.02
Starting training Variational Gaussian Process with a Bernoulli Likelihood with Logistic Link infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:07:52[K
  iter:  10
  ELBO:  -15.45496403516649[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:07:10[K
  iter:  20
  ELBO:  -12.921811247704284[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:07:49[K
  iter:  30
  ELBO:  -10.525979508342859[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:08:29[K
  iter:  40
  ELBO:  -8.358200907239684[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:07:52Training ended after 50 iterations. Total number of iterations 50
[K
  iter:  50
  ELBO:  -6.4397859300417934[A[Aâ”Œ Info: Classification Error
â””   err = 0.06
Starting training Variational Gaussian Process with a Logistic-Softmax Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 5 latent GPs
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = mapreduce_impl(::typeof(SpecialFunctions.lgamma), ::typeof(Base.add_sum), ::Array{Float64,1}, ::Int64, ::Int64, ::Int64) at reduce.jl:155
â”” @ Base .&#x2F;reduce.jl:155
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = mapreduce_impl(::typeof(SpecialFunctions.lgamma), ::typeof(Base.add_sum), ::Array{Float64,1}, ::Int64, ::Int64, ::Int64) at reduce.jl:155
â”” @ Base .&#x2F;reduce.jl:155
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = macro expansion at reduce.jl:158 [inlined]
â”” @ Core .&#x2F;reduce.jl:158
Training Progress:   2%|â–‹                               |  ETA: 0:46:16[K
  iter:  10
  ELBO:  -35.3935785497838[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:49:37[K
  iter:  20
  ELBO:  -34.450206095421095[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:47:17[K
  iter:  30
  ELBO:  -33.48761577222891[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:43:03[K
  iter:  40
  ELBO:  -32.511984642637856[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:38:58[K
  iter:  50
  ELBO:  -31.53238843149282[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Multiclass Error
â””   err = 0.27
Starting training Variational Gaussian Process with a Poisson Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapreduce_impl(::typeof(SpecialFunctions.lfactorial), ::typeof(Base.add_sum), ::SubArray{Int64,1,Array{Int64,1},Tuple{UnitRange{Int64}},true}, ::Int64, ::Int64, ::Int64) at reduce.jl:155
â”” @ Base .&#x2F;reduce.jl:155
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapreduce_impl(::typeof(SpecialFunctions.lfactorial), ::typeof(Base.add_sum), ::SubArray{Int64,1,Array{Int64,1},Tuple{UnitRange{Int64}},true}, ::Int64, ::Int64, ::Int64) at reduce.jl:155
â”” @ Base .&#x2F;reduce.jl:155
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = macro expansion at reduce.jl:158 [inlined]
â”” @ Core .&#x2F;reduce.jl:158
Training Progress:   2%|â–‹                               |  ETA: 0:05:26[K
  iter:  10
  ELBO:  -127.88298349900538[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:05:42[K
  iter:  20
  ELBO:  -127.29460423970174[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:05:58[K
  iter:  30
  ELBO:  -126.78849653826994[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:05:25[K
  iter:  40
  ELBO:  -126.35342619265279[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:05:38[K
  iter:  50
  ELBO:  -125.97784291753513[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 0.7098173135397451
Starting training Variational Gaussian Process with a Negative Binomial Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:02:44[K
  iter:  10
  ELBO:  -721.0880180049668[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:02:29[K
  iter:  20
  ELBO:  -722.0593597319065[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:02:03[K
  iter:  30
  ELBO:  -724.9942368244377[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:01:39[K
  iter:  40
  ELBO:  -729.9041714833297[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:01:47[K
  iter:  50
  ELBO:  -736.0449100226631[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 17.843017416604514
Starting training Sparse Variational Gaussian Process with a Gaussian likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:17:56[K
  iter:  10
  ELBO:  -17079.797227277842[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:11:32[K
  iter:  20
  ELBO:  -8599.597977234811[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:09:26[K
  iter:  30
  ELBO:  -5242.010884223601[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:07:50[K
  iter:  40
  ELBO:  -3289.1278946429925[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:06:51[K
  iter:  50
  ELBO:  -2128.361384061914[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.19166431205933365
Starting training Sparse Variational Gaussian Process with a Gaussian likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:07:24[K
  iter:  10
  ELBO:  -9899.639904103531[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:04:08[K
  iter:  20
  ELBO:  -5426.539173392311[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:03:46[K
  iter:  30
  ELBO:  -2843.9384952479813[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:04:06[K
  iter:  40
  ELBO:  -1750.2504312954447[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:03:47[K
  iter:  50
  ELBO:  -1244.9903501916276[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.19240798383401675
Starting training Sparse Variational Gaussian Process with a Student-t likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:04:01[K
  iter:  10
  ELBO:  -154.46487995526215[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:03:43[K
  iter:  20
  ELBO:  -154.20442389905529[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:04:15[K
  iter:  30
  ELBO:  -148.27646371341282[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:03:39[K
  iter:  40
  ELBO:  -144.721419278619[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:03:22[K
  iter:  50
  ELBO:  -149.6070600895724[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.37437043455267
Starting training Sparse Variational Gaussian Process with a Student-t likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:02:39[K
  iter:  10
  ELBO:  -153.04344847573242[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:04:24[K
  iter:  20
  ELBO:  -149.99639403772224[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:03:57[K
  iter:  30
  ELBO:  -147.7602417610451[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:03:38[K
  iter:  40
  ELBO:  -146.24357901950046[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:03:15[K
  iter:  50
  ELBO:  -145.29013276252704[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.41590173469563896
Starting training Sparse Variational Gaussian Process with a Laplace likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:00:48[K
  iter:  10
  ELBO:  -484.54426228743625[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:00:19[K
  iter:  30
  ELBO:  -529.6422203331739[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:00:16[K
  iter:  50
  ELBO:  -539.2752458689331[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.36679289894619643
Starting training Sparse Variational Gaussian Process with a Laplace likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:03:30[K
  iter:  10
  ELBO:  -532.2261019516801[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:04:25[K
  iter:  20
  ELBO:  -541.9117945690705[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:03:42[K
  iter:  30
  ELBO:  -550.4257458267432[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:03:35[K
  iter:  40
  ELBO:  -557.2638921738726[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:03:12[K
  iter:  50
  ELBO:  -562.3300006862518[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Regression Error
â””   err = 0.4045807937532465
Starting training Sparse Variational Gaussian Process with a Bayesian SVM infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:03:08[K
  iter:  10
  ELBO:  65.9218130002265[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:04:25[K
  iter:  20
  ELBO:  76.82715598619467[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:03:48[K
  iter:  30
  ELBO:  73.98349532366115[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:03:48[K
  iter:  40
  ELBO:  74.00915532136801[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:04:04[K
  iter:  50
  ELBO:  97.50413919760484[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Classification Error
â””   err = 0.08
Starting training Sparse Variational Gaussian Process with a Bayesian SVM infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:05:10[K
  iter:  10
  ELBO:  68.98355584076893[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:03:40[K
  iter:  20
  ELBO:  76.78745658806402[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:04:02[K
  iter:  30
  ELBO:  84.52423904711736[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:03:24[K
  iter:  40
  ELBO:  92.2066783805736[A[A

[K[ATraining ended after 50 iterations. Total number of iterations 50[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:03:33[K
  iter:  50
  ELBO:  99.92516828116736[A[A
â”Œ Info: Classification Error
â””   err = 0.1
Starting training Sparse Variational Gaussian Process with a Bernoulli Likelihood with Logistic Link infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:05:50[K
  iter:  10
  ELBO:  -27.751042546926456[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:05:03[K
  iter:  20
  ELBO:  -28.644634401176216[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:04:36[K
  iter:  30
  ELBO:  -27.546234465921838[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:04:31[K
  iter:  40
  ELBO:  -30.514751102705365[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:04:33[K
  iter:  50
  ELBO:  -24.39375109216409[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Classification Error
â””   err = 0.09
Starting training Sparse Variational Gaussian Process with a Bernoulli Likelihood with Logistic Link infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:04:54[K
  iter:  10
  ELBO:  -26.85480220115716[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:04:38[K
  iter:  20
  ELBO:  -25.465444295531924[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:03:45[K
  iter:  30
  ELBO:  -24.217839663708514[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:03:19[K
  iter:  40
  ELBO:  -23.223133523714495[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:03:35[K
  iter:  50
  ELBO:  -22.567557185060824[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Classification Error
â””   err = 0.12
Starting training Sparse Variational Gaussian Process with a Logistic-Softmax Likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 5 latent GPs
Training Progress:   2%|â–‹                               |  ETA: 0:21:08[K
  iter:  10
  ELBO:  -49.35338984675457[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:25:00[K
  iter:  20
  ELBO:  -41.16411651416668[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:23:02[K
  iter:  30
  ELBO:  -44.22525228539834[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:22:53[K
  iter:  40
  ELBO:  -43.97645560619186[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:19:49[K
  iter:  50
  ELBO:  -44.020038336192954[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Multiclass Error
â””   err = 0.15
Starting training Sparse Variational Gaussian Process with a Logistic-Softmax Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 5 latent GPs
Training Progress:   2%|â–‹                               |  ETA: 0:11:55[K
  iter:  10
  ELBO:  -36.0747705571992[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:13:22[K
  iter:  20
  ELBO:  -34.4478201922481[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:11:09[K
  iter:  30
  ELBO:  -32.80267257984208[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:10:22[K
  iter:  40
  ELBO:  -31.148706915774156[A[ATraining ended after 50 iterations. Total number of iterations 50


[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:11:28[K
  iter:  50
  ELBO:  -29.50121146723589[A[Aâ”Œ Info: Multiclass Error
â””   err = 0.33
Starting training Sparse Variational Gaussian Process with a Poisson Likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapreduce_first at reduce.jl:293 [inlined]
â”” @ Core .&#x2F;reduce.jl:293
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapfoldl_impl(::typeof(SpecialFunctions.lfactorial), ::typeof(Base.add_sum), ::NamedTuple{(:init,),Tuple{Float64}}, ::SubArray{Int64,1,Array{Int64,1},Tuple{Array{Int64,1}},false}, ::Tuple{Base.OneTo{Int64},Int64}) at reduce.jl:45
â”” @ Base .&#x2F;reduce.jl:45
â”Œ Warning: `lfactorial(x)` is deprecated, use `logfactorial(x)` instead.
â”‚   caller = mapfoldl_impl(::typeof(SpecialFunctions.lfactorial), ::typeof(Base.add_sum), ::NamedTuple{(:init,),Tuple{Float64}}, ::SubArray{Int64,1,Array{Int64,1},Tuple{Array{Int64,1}},false}, ::Tuple{Base.OneTo{Int64},Int64}) at reduce.jl:49
â”” @ Base .&#x2F;reduce.jl:49
Training Progress:   2%|â–‹                               |  ETA: 0:05:50[K
  iter:  10
  ELBO:  -139.15902420996977[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:04:39[K
  iter:  20
  ELBO:  -133.03364964276952[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:04:15[K
  iter:  30
  ELBO:  -140.48091147463396[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:04:39[K
  iter:  40
  ELBO:  -144.3885844875022[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:04:36[K
  iter:  50
  ELBO:  -141.88303814571918[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 0.7510338044696269
Starting training Sparse Variational Gaussian Process with a Poisson Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:00:33[K
  iter:  10
  ELBO:  -145.46229622545312[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:02:36[K
  iter:  20
  ELBO:  -144.11699398013732[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:01:56[K
  iter:  30
  ELBO:  -142.97528946376272[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:01:37[K
  iter:  40
  ELBO:  -142.03652823774968[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:01:36[K
  iter:  50
  ELBO:  -141.27613432017748[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 0.7455536649032818
Starting training Sparse Variational Gaussian Process with a Negative Binomial Likelihood infered by Analytic Stochastic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:04:53[K
  iter:  10
  ELBO:  -545.1836920779126[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:04:35[K
  iter:  20
  ELBO:  -431.2933407778883[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:03:51[K
  iter:  30
  ELBO:  -410.62566331071366[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:03:49[K
  iter:  40
  ELBO:  -416.3963375083516[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:03:38[K
  iter:  50
  ELBO:  -463.387603307715[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 7.459339822755598
Starting training Sparse Variational Gaussian Process with a Negative Binomial Likelihood infered by Analytic Variational Inference  with 100 samples with 2 features and 1 latent GP
Training Progress:   2%|â–‹                               |  ETA: 0:04:47[K
  iter:  10
  ELBO:  -432.4950813465152[A[A

[K[A[K[ATraining Progress:   4%|â–ˆâ–                              |  ETA: 0:05:45[K
  iter:  20
  ELBO:  -421.048391009173[A[A

[K[A[K[ATraining Progress:   6%|â–ˆâ–‰                              |  ETA: 0:04:53[K
  iter:  30
  ELBO:  -413.58238983648727[A[A

[K[A[K[ATraining Progress:   8%|â–ˆâ–ˆâ–Œ                             |  ETA: 0:04:01[K
  iter:  40
  ELBO:  -409.5425285298352[A[A

[K[A[K[ATraining Progress:  10%|â–ˆâ–ˆâ–ˆâ–                            |  ETA: 0:03:43[K
  iter:  50
  ELBO:  -408.2247063170046[A[ATraining ended after 50 iterations. Total number of iterations 50
â”Œ Info: Event Error
â””   err = 7.530005362003821
Test Summary:                      | Pass  Total
Augmented Gaussian Process Testing |   79     79
   Testing AugmentedGaussianProcesses tests passed 
</pre>
      </div>


  </div>
  </body>

  <script type="text/javascript">// handle collapsibles
var coll = document.getElementsByClassName("collapsible");
for (var i = 0; i < coll.length; i++) {
    coll[i].textContent = "â–¸ " + coll[i].textContent
    coll[i].addEventListener("click", function() {
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.display === "block") {
            this.textContent = "â–¸" + this.textContent.substr(1)
            content.style.display = "none";
        } else {
            this.textContent = "â–¾" + this.textContent.substr(1)
            content.style.display = "block";
        }
    });
}
</script>
</html>

